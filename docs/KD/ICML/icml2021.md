<h1>ICML List</h1>
<strong>[ICML 2021](https://icml.cc/Conferences/2021)</strong>

<ul>
<li>KD3A: Unsupervised Multi-Source Decentralized Domain Adaptation via Knowledge Distillation
<a href="">[paper]</a>
<li><a href="A statistical perspective on distillation">[paper]</a>
<li><a href="Training data-efficient image transformers & distillation through attention
">[paper]</a>
<li>Zero-Shot Knowledge Distillation from a Decision-Based Black-Box Model
<a href="">[paper]</a>
<li>Cross-model Back-translated Distillation for Unsupervised Machine Translation
<a href="">[paper]</a>
<li>Data-Free Knowledge Distillation for Heterogeneous Federated Learning
<a href="">[paper]</a>
<li>Simultaneous Similarity-based Self-Distillation for Deep Metric Learning
<a href="">[paper]</a>
<li>Model Distillation for Revenue Optimization: Interpretable Personalized Pricing
<a href="">[paper]</a>

</ul>
