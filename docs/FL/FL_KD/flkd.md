<h1>Federated Learning or Edge Computation with ML</h1>
<ul>
<li>Fedmd: Heterogenous federated learning via model distillation<a href="https://arxiv.org/pdf/1910.03581">[paper]</a>
<li>Communication-efficient on-device machine learning: Federated distillation and augmentation under non-iid private data<a href="https://arxiv.org/pdf/1811.11479">[paper]</a>
<li>Ensemble distillation for robust model fusion in federated learning<a href="https://papers.nips.cc/paper/2020/file/18df51b97ccd68128e994804f3eccc87-Supplemental.pdf">[paper]</a>
<li>Wireless federated distillation for distributed edge learning with heterogeneous data<a href="https://arxiv.org/pdf/1907.02745">[paper]</a>
<li>Federated Knowledge Distillation (???)<a href="https://arxiv.org/pdf/2011.02367.pdf">[paper]</a>
<li>Federated Learning with Heterogeneous Labels and Models for Mobile Activity Monitoring<a href="https://arxiv.org/pdf/2012.02539">[paper]</a>
<li>Hierarchical federated learning across heterogeneous cellular networks<a href="https://arxiv.org/pdf/1909.02362">[paper]</a>
<li>Federated Mutual Learning<a href="https://arxiv.org/pdf/2006.16765">[paper]</a>
<li>Model pruning enables efficient federated learning on edge devices<a href="https://arxiv.org/pdf/1909.12326">[paper]</a>
</ul>
