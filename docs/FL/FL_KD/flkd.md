<h1>Federated Learning or Edge Computation with ML</h1>
<ul>
<li>Fedmd: Heterogenous federated learning via model distillation<a href="https://arxiv.org/pdf/1910.03581">[paper]</a>
<li>Communication-efficient on-device machine learning: Federated distillation and augmentation under non-iid private data<a href="https://arxiv.org/pdf/1811.11479">[paper]</a>
<li>Ensemble distillation for robust model fusion in federated learning<a href="https://papers.nips.cc/paper/2020/file/18df51b97ccd68128e994804f3eccc87-Supplemental.pdf">[paper]</a>
<li>Wireless federated distillation for distributed edge learning with heterogeneous data<a href="https://arxiv.org/pdf/1907.02745">[paper]</a>
<li>Federated Knowledge Distillation (???)<a href="https://arxiv.org/pdf/2011.02367.pdf">[paper]</a>
<li>Federated Learning with Heterogeneous Labels and Models for Mobile Activity Monitoring<a href="https://arxiv.org/pdf/2012.02539">[paper]</a>
<li>Hierarchical federated learning across heterogeneous cellular networks<a href="https://arxiv.org/pdf/1909.02362">[paper]</a>
<li>Federated Mutual Learning<a href="https://arxiv.org/pdf/2006.16765">[paper]</a>
<li>Model pruning enables efficient federated learning on edge devices<a href="https://arxiv.org/pdf/1909.12326">[paper]</a>

<strong>FL on [CVPR 2021](http://cvpr2021.thecvf.com/)</strong>

<li>Model-Contrastive Federated Learning<a href="">[paper_tobe_updated]</a>

<strong>FL on [ICLR 2021](https://iclr.cc/)</strong>

<li>Federated Learning Based on Dynamic Regularization<a href="https://openreview.net/pdf?id=B7v4QMR6Z9w">[paper]</a>
<li>Federated Learning via Posterior Averaging: A New Perspective and Practical Algorithms<a href="https://openreview.net/pdf?id=GFsU8a0sGB">[paper]</a>
<li>Adaptive Federated Optimization<a href="https://openreview.net/pdf?id=LkFG3lB13U5">[paper]</a>
<li>Achieving Linear Speedup with Partial Worker Participation in Non-IID Federated Learning<a href="https://openreview.net/pdf?id=jDdzh5ul-d">[paper]</a>
<li>Federated Semi-Supervised Learning with Inter-Client Consistency & Disjoint Learning<a href="https://openreview.net/pdf?id=ce6CFXBh30h">[paper]</a>
<li>FedBN: Federated Learning on Non-IID Features via Local Batch Normalization <a href="https://openreview.net/pdf?id=6YEQUn0QICG">[paper]</a>
<li>FedBE: Making Bayesian Model Ensemble Applicable to Federated Learning<a href="https://openreview.net/pdf?id=dgtpE6gKjHn">[paper]</a>
<li>FedMix: Approximation of Mixup under Mean Augmented Federated Learning<a href="https://openreview.net/pdf?id=Ogga20D2HO-">[paper]</a>
<li>HeteroFL: Computation and Communication Efficient Federated Learning for Heterogeneous Clients <a href="https://openreview.net/pdf?id=TNkPBBYFkXg">[paper]</a>
<li>Personalized Federated Learning with First Order Model Optimization<a href="https://openreview.net/pdf?id=ehJqJQk9cw">[paper]</a>

<strong>FL interesting framework</strong>
<li>:star:Split learning for health: Distributed deep learning without sharing raw patient data <a href="https://proceedings.neurips.cc/paper/2020/file/a1d4c20b182ad7137ab3606f0e3fc8a4-Paper.pdf">[paper]</a>

<li>:star:Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge <a href="https://proceedings.neurips.cc/paper/2020/file/a1d4c20b182ad7137ab3606f0e3fc8a4-Paper.pdf">[paper]</a>

<li>Split learning for collaborative deep learning in healthcare<a href="https://arxiv.org/pdf/1912.12115">[paper]</a>

<li>Splitfed: When federated learning meets split learning<a href="https://arxiv.org/pdf/2004.12088">[paper]</a>

<li>Detailed comparison of communication efficiency of split learning and federated learning <a href="https://arxiv.org/pdf/1909.09145">[paper]</a>


</ul>

<strong>FL on [ICML 2020](https://icml.cc/virtual/2020/)</strong>
<ul>
<li>Federated Learning with Only Positive Labels<a href="http://proceedings.mlr.press/v119/yu20f/yu20f.pdf">[paper]</a>
<li>FetchSGD: Communication-Efficient Federated Learning with Sketching<a href="http://proceedings.mlr.press/v119/rothchild20a/rothchild20a.pdf">[paper]</a>
<li>SCAFFOLD: Stochastic Controlled Averaging for Federated Learning<a href="http://proceedings.mlr.press/v119/karimireddy20a/karimireddy20a.pdf">[paper]</a>
<li>From Local SGD to Local Fixed-Point Methods for Federated Learning<a href="http://proceedings.mlr.press/v119/malinovskiy20a/malinovskiy20a.pdf">[paper]</a>
<li>FedBoost: A Communication-Efficient Algorithm for Federated Learning<a href="http://proceedings.mlr.press/v119/hamer20a/hamer20a.pdf">[paper]</a>

</ul>